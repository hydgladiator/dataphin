# 约束与限制

在使用Dataphin前，建议您先了解产品相关使用限制，确保业务可顺利开展。本文为您介绍使用Dataphin过程中的操作限制。

## 浏览器限制

您需要使用Google Chrome浏览器60.x及以上版本登录Dataphin。

## 使用限制

为保障软件系统稳定，Dataphin有部分使用上的限制或建议，详情如下表所示。

|功能项|操作项|使用限制/建议|
|---|---|-------|
|管理中心|成员管理|-   超级管理员（即超管）是您购买Dataphin后，由系统初始化自动生成的角色。
    -   您的阿里云主账号即为超级管理员账号，通过**访问控制**功能可以创建RAM用户，详情请参见[创建RAM用户](/cn.zh-CN/准备工作/创建RAM用户.md)。
    -   一个Dataphin系统只有一个超级管理员账号，拥有系统内所有权限。
-   阿里云RAM账号体系下，如果要更新用户列表、用户信息，则需要进行如下操作：
    1.  使用超级管理员账号登录[管理控制台介绍](/cn.zh-CN/管理控制台/管理控制台介绍.md)，配置Access Key做授权。
    2.  使用超级管理员账号执行**账号系统同步**，即可获取阿里云主账号下的RAM子账号，并添加为Dataphin的成员。 |
|管理中心|配置计算引擎|-   全局配置只支持在系统内计算引擎源为空的情况下，由超管更新。
-   MaxCompute计算引擎类型下，Endpoint地址配置详情请参见[Endpoint](/cn.zh-CN/准备工作/Endpoint.md)。 |
|计算引擎类型|选择设置|计算引擎设置需要提前采购计算引擎MaxCompute资源，系统以此来支持相关数据的建设工作。 -   需要选择计算引擎类型（目前仅开放MaxCompute计算类型），配置计算引擎所在的集群，例如Endpoint等信息。系统以此来支持该计算引擎类型下、该集群上，相关数据的建设工作。请根据您的计算引擎的集群情况选择设置。
-   如果您需要用到Spark on MaxCompute做计算，建议提交工单咨询，确认您的MaxCompute计算引擎所在的地域（Region）是否开通Spark服务。如果该地域未开通Spark服务，您的Spark任务将无法成功执行。
-   请您以Dataphin为唯一入口进行数据构建与管理，以免出现元数据错误、权限异常等问题。

**说明：** 创建MaxCompute项目的具体方法请参见[创建MaxCompute项目](/cn.zh-CN/准备工作/创建MaxCompute项目.md)。 |
|数据源管理|新增数据源|-   建议配置的数据源Access Key为管理级权限。可以通过配置主账号Access Key，或者给子账号Access Key授予MaxCompute所有权限来实现。
-   不建议将同一个物理数据库（配置完全相同）配为两个数据源。 |
|项目管理|项目名称|-   建议当配置数据源为MaxCompute类型时，项目英文名必须与MaxCompute的Project英文名一致。
-   项目名不可以`LD_`/`ld_`开始，以免与业务板块名冲突，导致查询功能不可用。 |
|项目管理|配置计算引擎源|-   对于已配置为项目数据源的物理数据库，不建议再从其他非Dataphin控制台进行数据的增、删、改操作。
-   不建议您为项目配置跨集群的计算引擎源。 |
|研发工作台|规范建模|-   建议您谨慎命名规范定义和逻辑表对象的英文名，且推荐使用小写英文字母命名，以免因下游依赖约束导致英文名不可改且不易读。
-   请尽可能使用英文缩写，以免字段名称超出数据库限制，导致数据生产出错。 |
|研发工作台|数据处理|-   不支持项目所属的计算引擎源在跨集群的情况下读取数据。
-   非Dataphin创建的表，Dataphin中元数据可能无法获取或者更新相关信息。 |
|研发工作台|即席查询|逻辑表查询时，必须使用业务板块的英文名作为前缀。跨项目物理表使用时，必须使用项目的英文名作为前缀。 如果您需要查询开发环境数据，请在生产名称后加上**\_dev**，系统会自动将生产业务板块、生产项目生成对应的变量。例如，您拥有业务板块LD\_Trade，则系统自动生成业务板块变量$\{LD\_Trade\}。该变量在开发环境执行时默认被替换为LD\_Trade\_dev，在生产环境执行时默认被替换为LD\_Trade。您也可以在执行时设置固定的值，提高代码在不同环境执行时的灵活性。 |

