# 使用限制 {#concept_av1_vrt_zgb .concept}

本文为您介绍Dataphin的使用限制。

为保障软件系统稳定，Dataphin有部分使用上的限制或建议，详情如下表所示。

|功能项|操作项|使用限制/建议|
|---|---|-------|
|管理中心|成员管理| -   超级管理员（即超管）是您购买Dataphin后，由系统初始化自动生成的角色。
    -   您的阿里云主账号即为超级管理员账号，通过**访问控制**功能可以创建RAM子账号，详情参见[准备RAM子账号](../../../../cn.zh-CN/准备工作/准备RAM子账号.md#)。
    -   一个Dataphin系统只有一个超级管理员账号，拥有系统内所有权限。
-   阿里云RAM账号体系下，如果要更新用户列表、用户信息，则需要进行如下操作：
    1.  使用超级管理员账号登录[管理控制台](../../../../cn.zh-CN/用户指南/界面引导/管理控制台.md#)，配置Access Key做授权。
    2.  使用超级管理员账号执行**账号系统同步**，即可获取阿里云主账号下的RAM子账号，并添加为Dataphin的成员。

 |
|管理中心|配置计算引擎| -   全局配置只支持在系统内计算引擎源为空的情况下，由超管更新。
-   MaxCompute计算类型下，推荐配置Endpoint为http://service.cn.。如果您需要使用数据萃取功能（公测期间，数据萃取功能暂未全面开放使用），建议咨询MaxCompute产品售后，确认您数据中心所在地域（Region）支持Spark的Endpoint地址。

 |
|计算引擎类型|选择设置|计算引擎设置需要提前采购计算引擎MaxCompute资源，系统以此来支持相关数据的建设工作。 -   需要选择计算引擎类型（目前开放MaxCompute），配置计算引擎所在的集群，例如Endpoint等信息。系统以此来支持该计算引擎类型下、该集群上，相关数据的建设工作。请根据您的计算引擎的集群情况选择设置。
-   如果您需要用到Spark on MaxCompute做计算，请咨询MaxCompute产品售后，确认您的MaxCompute计算引擎所在的地域（Region）是否开通Spark服务。如果该地域未开通Spark服务，您的Spark任务将无法成功执行。
-   请您以Dataphin为唯一入口进行数据构建与管理，以免出现元数据错误、权限异常等问题。

 **说明：** 创建MaxCompute项目的具体方法请参见[创建项目](../../../../cn.zh-CN/准备工作/创建项目.md#)。

 |
|数据源管理|新增数据源| -   建议配置的数据源Access Key为管理级权限。可以通过配置主账号Access Key，或者给子账号Access Key授予MaxCompute所有权限来实现。
-   不建议将同一个物理数据库（配置完全相同）配为两个数据源。

 |
|项目管理|项目名称| -   建议当配置数据源为MaxCompute类型时，项目英文名必须与MaxCompute的Project英文名一致。
-   项目名不可以`LD_`/`ld_`开始，以免与业务板块名冲突，导致查询功能不可用。

 |
|项目管理|配置计算引擎源| -   对于已配置为项目数据源的物理数据库，不建议再从其他非Dataphin控制台进行数据的增、删、改操作。
-   不建议您为项目配置跨集群的计算引擎源。

 |
|研发工作台|规范建模| -   建议您谨慎命名规范定义和逻辑表对象的英文名，且推荐使用小写英文字母命名，以免因下游依赖约束导致英文名不可改且不易读。
-   请尽可能使用英文缩写，以免字段名称超出数据库限制，导致数据生产出错。

 |
|研发工作台|数据处理| -   不支持项目所属的计算引擎源在跨集群的情况下读取数据。
-   非Dataphin创建的表，Dataphin中元数据可能无法获取或者更新相关信息。

 |
|研发工作台|即席查询|逻辑表查询时，必须使用业务板块的英文名作为前缀。跨项目物理表使用时，必须使用项目的英文名作为前缀。 如果您需要查询开发环境数据，请在生产名称后加上**\_dev**，系统会自动将生产业务板块、生产项目生成对应的变量。例如，您拥有业务板块LD\_Trade，则系统自动生成业务板块变量$\{LD\_Trade\}。该变量在开发环境执行时默认被替换为LD\_Trade\_dev，在生产环境执行时默认被替换为LD\_Trade。您也可以在执行时设置固定的值，提高代码在不同环境执行时的灵活性。

 |

